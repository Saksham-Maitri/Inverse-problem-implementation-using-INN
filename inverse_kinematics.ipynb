{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q--4Kt1bN8ZW",
        "outputId": "f4c64eff-3921-49a6-c40f-9107968386da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for FrEIA (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q matplotlib torch FrEIA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device\", device)\n",
        "\n",
        "def subnet_fc(dims_in, dims_out):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(dims_in, 256), nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256, dims_out)\n",
        "    )\n",
        "\n",
        "def INN(num_joints=4):\n",
        "    nodes = [Ff.InputNode(num_joints, name='input')]\n",
        "    for k in range(10):\n",
        "        nodes.append(Ff.Node(nodes[-1],\n",
        "                             Fm.PermuteRandom,\n",
        "                             {'seed': k},\n",
        "                             name=f'perm_{k}'))\n",
        "        nodes.append(Ff.Node(nodes[-1],\n",
        "                             Fm.GLOWCouplingBlock,\n",
        "                             {'subnet_constructor': subnet_fc, 'clamp': 1.9},\n",
        "                             name=f'glow_{k}'))\n",
        "    nodes.append(Ff.OutputNode(nodes[-1], name='output'))\n",
        "    return Ff.GraphINN(nodes)\n",
        "\n",
        "def end_edductor_pos(clampps,theta1,theta2,theta3):\n",
        "  l1=0.5\n",
        "  l2=0.5\n",
        "  l3=1.0\n",
        "  x_coordinate = l1 * torch.cos(theta1) + l2 * torch.cos(theta2 - theta1) + l3 * torch.cos(theta3 - theta1 - theta2)\n",
        "  y_coordinate = clampps + l1 * torch.sin(theta1) + l2 * torch.sin(theta2 - theta1) + l3 * torch.sin(theta3 - theta1 - theta2)\n",
        "  return x_coordinate, y_coordinate\n",
        "\n",
        "import torch\n",
        "\n",
        "def end_effector_pos(clampps, theta1, theta2, theta3):\n",
        "    l1 = 0.5\n",
        "    l2 = 0.5\n",
        "    l3 = 1.0\n",
        "    y = clampps + l1 * torch.sin(theta1) + l2 * torch.sin(theta2 - theta1) + l3 * torch.sin(theta3 - theta1 - theta2)\n",
        "    x = l1 * torch.cos(theta1) + l2 * torch.cos(theta2 - theta1) + l3 * torch.cos(theta3 - theta1 - theta2)\n",
        "    return x, y\n",
        "\n",
        "def train_set(n_samples=1000):\n",
        "    sigma1 = 0.25\n",
        "    sigma_others = 0.5\n",
        "    x1 = torch.randn(n_samples) * sigma1\n",
        "    x2 = torch.randn(n_samples) * sigma_others\n",
        "    x3 = torch.randn(n_samples) * sigma_others\n",
        "    x4 = torch.randn(n_samples) * sigma_others\n",
        "\n",
        "    y1, y2 = end_effector_pos(x1, x2, x3, x4)\n",
        "\n",
        "    x = torch.stack([x1, x2, x3, x4], dim=1)\n",
        "    y = torch.stack([y1, y2], dim=1)\n",
        "    return x, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii9ZhLznOuHZ",
        "outputId": "f872fe35-bb5b-429a-deee-52b291cb9ccc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, x_train, y_train, n_epochs=1, batch_size=512, lr=1e-4, weight_fk=10.0, weight_latent=1.0, weight_rev=5.0):\n",
        "    print(\"Starting INN training...\")\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "    latent_dim = 2  # Number of latent variables\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print('Current epoch',epoch)\n",
        "        model.train()\n",
        "        epoch_loss_f = 0.0\n",
        "        epoch_loss_z = 0.0\n",
        "        epoch_loss_rev = 0.0\n",
        "        epoch_loss_total = 0.0\n",
        "\n",
        "        n_batches = max(1, len(x_train) // batch_size)\n",
        "\n",
        "        for i in tqdm(range(n_batches)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get batch\n",
        "            start = i * batch_size\n",
        "            end = min(len(x_train), (i + 1) * batch_size)\n",
        "            x_batch = x_train[start:end].to(device)\n",
        "            y_batch_gt = y_train[start:end].to(device)\n",
        "\n",
        "            # --- Forward Pass ---\n",
        "            out_inn_tensor, _ = model(x_batch)\n",
        "            y_pred = out_inn_tensor[:, :2]\n",
        "            z_pred = out_inn_tensor[:, 2:]\n",
        "\n",
        "            loss_f = mse_loss(y_pred, y_batch_gt)\n",
        "            loss_z = torch.mean(z_pred ** 2) / 2.0\n",
        "\n",
        "            # --- Reverse Pass ---\n",
        "            z_rev_sample = torch.randn(len(x_batch), latent_dim, device=device)\n",
        "            rev_input = torch.cat((y_batch_gt, z_rev_sample), dim=1)\n",
        "            x_rev_pred_tensor, _ = model(rev_input, rev=True)\n",
        "\n",
        "            y1, y2 = end_effector_pos(x_rev_pred_tensor[:, 0],\n",
        "                                      x_rev_pred_tensor[:, 1],\n",
        "                                      x_rev_pred_tensor[:, 2],\n",
        "                                      x_rev_pred_tensor[:, 3])\n",
        "            y_rev_pred = torch.stack([y1, y2], dim=1)\n",
        "\n",
        "            loss_rev = mse_loss(y_rev_pred, y_batch_gt)\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = weight_fk * loss_f + weight_latent * loss_z + weight_rev * loss_rev\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate losses\n",
        "            epoch_loss_f += loss_f.item()\n",
        "            epoch_loss_z += loss_z.item()\n",
        "            epoch_loss_rev += loss_rev.item()\n",
        "            epoch_loss_total += total_loss.item()\n",
        "\n",
        "            if (i + 1) % max(1, n_batches // 10) == 0 or i == n_batches - 1:\n",
        "                print(f\" Batch {i+1}/{n_batches} - Loss: {total_loss.item():.4f} \"\n",
        "                      f\"(Fk:{loss_f.item():.4f}, Z:{loss_z.item():.4f}, Rev:{loss_rev.item():.4f})\", end='\\r')\n",
        "\n",
        "        # Log epoch summary\n",
        "        avg_epoch_loss = epoch_loss_total / n_batches\n",
        "        avg_epoch_loss_f = epoch_loss_f / n_batches\n",
        "        avg_epoch_loss_z = epoch_loss_z / n_batches\n",
        "        avg_epoch_loss_rev = epoch_loss_rev / n_batches\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs} - Time: {elapsed_time:.1f}s \" f\"- Train Loss: {avg_epoch_loss:.4f} (F:{avg_epoch_loss_f:.4f}, Z:{avg_epoch_loss_z:.4f}, R:{avg_epoch_loss_rev:.4f})\")\n",
        "\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "66eLjRtwPs0V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = INN()\n",
        "model.to(device) # Move the model to the appropriate device\n",
        "x_train, y_train = train_set(1000)\n",
        "x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "train_model(model, x_train, y_train, n_epochs=10, batch_size=512, lr=1e-4, weight_fk=10.0, weight_latent=1.0, weight_rev=5.0)\n",
        "# save model\n",
        "torch.save(model.state_dict(), 'robot_arm.pth')\n",
        "\n",
        "# load model for testing\n",
        "model = INN()\n",
        "model.load_state_dict(torch.load('robot_arm.pth'))\n",
        "model.to(device) # Move the loaded model to the appropriate device\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2ytjDeFVaHM",
        "outputId": "a5188b47-a06d-4d38-ec52-a2329a063a8d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting INN training...\n",
            "Current epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 30.1654 (Fk:1.5503, Z:0.1084, Rev:2.9108)\r\n",
            "Epoch 1/10 - Time: 0.9s - Train Loss: 30.1654 (F:1.5503, Z:0.1084, R:2.9108)\n",
            "Current epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 22.7371 (Fk:1.2405, Z:0.1105, Rev:2.0444)\r\n",
            "Epoch 2/10 - Time: 0.9s - Train Loss: 22.7371 (F:1.2405, Z:0.1105, R:2.0444)\n",
            "Current epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 18.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 18.7019 (Fk:0.9810, Z:0.1175, Rev:1.7548)\r\n",
            "Epoch 3/10 - Time: 1.0s - Train Loss: 18.7019 (F:0.9810, Z:0.1175, R:1.7548)\n",
            "Current epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 15.7638 (Fk:0.7597, Z:0.1382, Rev:1.6057)\r\n",
            "Epoch 4/10 - Time: 1.1s - Train Loss: 15.7638 (F:0.7597, Z:0.1382, R:1.6057)\n",
            "Current epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 17.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 13.8767 (Fk:0.5777, Z:0.1692, Rev:1.5861)\r\n",
            "Epoch 5/10 - Time: 1.1s - Train Loss: 13.8767 (F:0.5777, Z:0.1692, R:1.5861)\n",
            "Current epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 12.4899 (Fk:0.4530, Z:0.2107, Rev:1.5499)\r\n",
            "Epoch 6/10 - Time: 1.2s - Train Loss: 12.4899 (F:0.4530, Z:0.2107, R:1.5499)\n",
            "Current epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 19.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 12.2290 (Fk:0.4113, Z:0.2518, Rev:1.5727)\r\n",
            "Epoch 7/10 - Time: 1.2s - Train Loss: 12.2290 (F:0.4113, Z:0.2518, R:1.5727)\n",
            "Current epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 12.7152 (Fk:0.4412, Z:0.2689, Rev:1.6068)\r\n",
            "Epoch 8/10 - Time: 1.3s - Train Loss: 12.7152 (F:0.4412, Z:0.2689, R:1.6068)\n",
            "Current epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 12.3104 (Fk:0.4611, Z:0.2553, Rev:1.4889)\r\n",
            "Epoch 9/10 - Time: 1.4s - Train Loss: 12.3104 (F:0.4611, Z:0.2553, R:1.4889)\n",
            "Current epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 18.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Batch 1/1 - Loss: 323.2849 (Fk:0.4512, Z:0.2284, Rev:63.7089)\r\n",
            "Epoch 10/10 - Time: 1.4s - Train Loss: 323.2849 (F:0.4512, Z:0.2284, R:63.7089)\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphINN(\n",
              "  (module_list): ModuleList(\n",
              "    (0): PermuteRandom()\n",
              "    (1): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (2): PermuteRandom()\n",
              "    (3): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (4): PermuteRandom()\n",
              "    (5): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (6): PermuteRandom()\n",
              "    (7): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (8): PermuteRandom()\n",
              "    (9): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (10): PermuteRandom()\n",
              "    (11): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (12): PermuteRandom()\n",
              "    (13): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (14): PermuteRandom()\n",
              "    (15): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (16): PermuteRandom()\n",
              "    (17): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (18): PermuteRandom()\n",
              "    (19): GLOWCouplingBlock(\n",
              "      (subnet1): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "      (subnet2): Sequential(\n",
              "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (3): LeakyReLU(negative_slope=0.1)\n",
              "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_x(model , x_test):\n",
        "  with torch.no_grad():\n",
        "    x_test = x_test.to(device)\n",
        "    out_inn_tensor, _ = model(x_test)\n",
        "    y_pred = out_inn_tensor[:, :2]\n",
        "    z_pred = out_inn_tensor[:, 2:]\n",
        "    return y_pred, z_pred\n",
        "\n",
        "# Example usage\n",
        "\n",
        "x_test = torch.randn(1, 4)\n",
        "y_pred, z_pred = infer_x(model, x_test)\n",
        "print(\"y_pred:\", y_pred)\n",
        "print(\"z_pred:\", z_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIDEbBR1hCBI",
        "outputId": "9bd2da23-e24d-4912-8e3d-637df3fa29a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred: tensor([[ 0.8257, -0.5086]], device='cuda:0')\n",
            "z_pred: tensor([[ 0.7319, -0.0539]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def infer_y(model, y_test, n_samples=100):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    y_test = y_test.to(device)\n",
        "    if y_test.dim() == 1:\n",
        "        y_test = y_test.unsqueeze(0)\n",
        "    elif y_test.dim() != 2 or y_test.shape[1] != 2:\n",
        "        raise ValueError(f\"y_test should have shape [batch_size, 2] or [1, 2], but got {y_test.shape}\")\n",
        "\n",
        "    batch_size = y_test.shape[0]\n",
        "    y_dim = y_test.shape[1]\n",
        "    x_dim = model.dims_in[0][0]\n",
        "    latent_dim = x_dim - y_dim\n",
        "\n",
        "    if latent_dim <= 0:\n",
        "        raise ValueError(f\"Calculated latent dimension ({latent_dim}) is not positive. \"\n",
        "                         f\"Check model input dimension ({x_dim}) and y_test dimension ({y_dim}).\")\n",
        "\n",
        "    z_samples = torch.randn(batch_size, n_samples, latent_dim, device=device)\n",
        "    y_test_expanded = y_test.unsqueeze(1).expand(-1, n_samples, -1)\n",
        "    rev_input = torch.cat((y_test_expanded, z_samples), dim=2)\n",
        "    total_samples = batch_size * n_samples\n",
        "    rev_input_flat = rev_input.view(total_samples, x_dim)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x_pred_flat, _ = model(rev_input_flat, rev=True)\n",
        "\n",
        "    x_pred = x_pred_flat.view(batch_size, n_samples, x_dim)\n",
        "\n",
        "    if batch_size == 1:\n",
        "        x_pred = x_pred.squeeze(0)\n",
        "\n",
        "    return x_pred\n",
        "\n",
        "# Example usage\n",
        "y_test = torch.randn(1, 2)\n",
        "x_pred = infer_y(model, y_test)\n",
        "points = []\n",
        "for config in x_pred:\n",
        "  x_cor,y_cor = end_effector_pos(config[0], config[1], config[2], config[3])\n",
        "  points.append([x_cor,y_cor])\n",
        "\n",
        "# cuda to cpu\n",
        "points = [[point[0].cpu().numpy(), point[1].cpu().numpy()] for point in points]\n",
        "\n",
        "# plot the points\n",
        "plt.scatter([point[0] for point in points], [point[1] for point in points])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "8gso5mvghnF4",
        "outputId": "38bc6cc6-2cf8-4d92-85bf-dbc8f026738a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DxgAgnV9AUGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}